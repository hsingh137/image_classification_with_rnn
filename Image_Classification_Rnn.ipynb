{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZfAqAeqF4BMHI8b0+zXYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsingh137/image_classification_with_rnn/blob/main/Image_Classification_Rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGk5IwHIo5uX",
        "outputId": "a1e89b06-bcd7-4cb2-bcf4-0afe13aba0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: idx2numpy in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=7eb8297f5c39aef7f3ae927ee699159f2458df425195343d4f2cd4130fa51938\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "# manual installation of PyTorch library\n",
        "!pip3 install torch torchvision idx2numpy torchviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim  as optim\n",
        "import idx2numpy\n",
        "\n",
        "import gzip\n",
        "from torchviz import make_dot\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "t7MYkPrbpimB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Explore dataset "
      ],
      "metadata": {
        "id": "wVBlDY0ItFUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all transformations\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "\n",
        "# download and load training dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True , transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LOeiZD_pkuT",
        "outputId": "56848a4b-9212-4a74-8b78-96d741032c5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 176641307.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 99047991.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 207217719.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4014863.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Viewing some images "
      ],
      "metadata": {
        "id": "e10okIKWJ4bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(idx, tdata , label_data):\n",
        "  test_img = tdata[idx]\n",
        "  label = label_data[idx]\n",
        "\n",
        "  test_img = test_img.numpy()\n",
        "  print('Number is:' , label)\n",
        "  plt.imshow(test_img)"
      ],
      "metadata": {
        "id": "Y-w-sa_pvIbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_img(1, trainset.data , trainset.targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "SqWN-osNvguL",
        "outputId": "65d715d0-4f38-468a-f058-6676cc26ba46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number is: tensor(0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_img(599, trainset.data , trainset.targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "SNBpAqVJ6MXe",
        "outputId": "374a5661-4324-4946-dea5-031042921c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number is: tensor(7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform( transforms.ToTensor()(np.array(arr[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "MgCxxeskIK2-",
        "outputId": "31c8b5fb-9822-4250-f345-afdd7dd73560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-179-2a9fbed52cd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pic should be PIL Image or ndarray. Got {type(pic)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a trainloader"
      ],
      "metadata": {
        "id": "gd3z4ba1J9R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_file , lbl_file  , transform = None):\n",
        "      self.train_arr = idx2numpy.convert_from_file(img_file)\n",
        "      self.lbl_arr = idx2numpy.convert_from_file(lbl_file)\n",
        "\n",
        "       # adding transform \n",
        "      self.transform = transform\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self , idx):\n",
        "      # need to add transform \n",
        "        if transform: \n",
        "          img = np.array(self.train_arr[idx])\n",
        "          img = self.transform(img)\n",
        "        else: \n",
        "          print('return you need to add a transforms for the train data ')\n",
        "        target = self.lbl_arr[idx]\n",
        "        return img , target\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.lbl_arr)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dmF-RS8lzIfT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_file = '/content/data/MNIST/raw/train-images-idx3-ubyte'\n",
        "lbl_file = '/content/data/MNIST/raw/train-labels-idx1-ubyte'\n",
        "\n",
        "trainset = ImageDataset(img_file = train_file , lbl_file = lbl_file  , transform = transforms.ToTensor())\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "reHYi-fVJd_W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/data/MNIST/raw/t10k-images-idx3-ubyte'\n",
        "test_lbl_file = '/content/data/MNIST/raw/t10k-labels-idx1-ubyte'\n",
        "\n",
        "testset = ImageDataset(img_file = test_file , lbl_file = test_lbl_file  , transform = transforms.ToTensor())\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "C1KsZK6Fw8dY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(trainloader))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fK5o_0fmX_2",
        "outputId": "a3ceb2d8-4363-43de-9a2c-19cf79b99b0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(testloader))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi4aIZMSYcxv",
        "outputId": "bf96c6dd-2be5-4739-a908-9fc9b73c19c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN class"
      ],
      "metadata": {
        "id": "I44d-ro48Th-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9yUs9Vab4WQ",
        "outputId": "8844d899-3e3b-4c3d-965e-067db7d13926"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageRNN(nn.Module):\n",
        "  def __init__(self, input_size , hidden_dim, output_size):\n",
        "    # this is where the parameters of the model go \n",
        "    super(ImageRNN, self).__init__()\n",
        "\n",
        "    self.input_size = input_size \n",
        "    self.hidden_dim = hidden_dim \n",
        "    self.output_size = output_size \n",
        "\n",
        "    self.RNN = nn.RNN(self.input_size , self.hidden_dim  , batch_first = True)\n",
        "\n",
        "    self.fc = nn.Linear(self.hidden_dim ,  self.output_size)\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "      # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "      # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "      self.batch_size= batch_size\n",
        "      hidden = torch.rand(1, batch_size, self.hidden_dim)\n",
        "      return hidden\n",
        "\n",
        "\n",
        "  def forward(self , x ):\n",
        "    # get batch_size\n",
        "    batch_size = x.size(0)\n",
        "    # x = x.permute(1, 0, 2) \n",
        "    # x = x.view()\n",
        "\n",
        "    # initalise hidden state\n",
        "    hidden = self.init_hidden(batch_size)\n",
        "\n",
        "    # feed rnn \n",
        "    _ , hidden = self.RNN(x , hidden)\n",
        "  \n",
        "    # classify \n",
        "    out = self.fc(hidden)\n",
        "    # out = out.squeeze()\n",
        "\n",
        "    return out.view( -1 , self.output_size)\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "8uvZXCKO754k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test model "
      ],
      "metadata": {
        "id": "GhbMeKgvb-Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_size = 28\n",
        "hidden_dim = 30\n",
        "output_size =  10\n",
        "batch_size = 64 "
      ],
      "metadata": {
        "id": "HPZif4_HkvFD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images , label = next(dataiter)\n",
        "images = images.view(batch_size , -1, input_size)\n",
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez-hExVEm17I",
        "outputId": "8c74e676-3355-4233-d9a4-6f3cae7f84d9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model0 = ImageRNN(input_size, hidden_dim, output_size)"
      ],
      "metadata": {
        "id": "k5zTiCCjlS_r"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model0(images)"
      ],
      "metadata": {
        "id": "7kkUPTPihWnz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-HSns_HGlDp",
        "outputId": "74b77baa-427f-4a52-b790-f8d11f87b274"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(y.mean(), params=dict(model0.named_parameters())).render(\"attached\", format=\"png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7cncSc2cIcWf",
        "outputId": "8b371dba-a1f7-4785-bee5-0a16f4576a82"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'attached.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "sLzMOFAsb_8W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_si59OpcBTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model0 = ImageRNN(input_size, hidden_dim, output_size)"
      ],
      "metadata": {
        "id": "LlakoQ1on3p_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param0 = list(model0.parameters())\n",
        "param = list(model.parameters())"
      ],
      "metadata": {
        "id": "rcDo45oijabU"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "adam = optim.Adam(model0.parameters() , lr = 0.001)"
      ],
      "metadata": {
        "id": "ukWr9AEBnkJI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 3"
      ],
      "metadata": {
        "id": "1vzmbbxroBiW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(0, n_epochs , 1): \n",
        "  total_loss = 0 \n",
        "  train_acc = 0.0\n",
        "  model0.train()\n",
        "\n",
        "  for i, data  in enumerate(trainloader):\n",
        "    # initalize the loss\n",
        "    adam.zero_grad()\n",
        "\n",
        "    # get the data\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(batch_size , -1,1)\n",
        "\n",
        "        \n",
        "\n",
        "    # forward\n",
        "    preds = model0(inputs)\n",
        "\n",
        "    # calcualte loss\n",
        "    loss = criterion(preds, labels)\n",
        "    loss.backward()\n",
        "    adam.step()\n",
        "\n",
        "    # add loss\n",
        "    \n",
        "    total_loss += loss.detach().item()\n",
        "\n",
        "    # calucalte accuracy \n",
        "    out_labels = torch.argmax(preds, 1).data\n",
        "    correct  = (out_labels == labels ).sum()\n",
        "    train_acc += correct\n",
        "\n",
        "    if i%5 == 0 and i!=0:\n",
        "      print(f'{i}: {total_loss/i} ') \n",
        "\n",
        "  print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \n",
        "          %(epoch, total_loss/i, (train_acc/(i*64))*100 ))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mqrk2VGkoDTZ",
        "outputId": "0b50997a-4c95-4319-a83c-d129231b8f5f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5: 2.757499885559082 \n",
            "10: 2.5335843563079834 \n",
            "15: 2.457193152109782 \n",
            "20: 2.4181712746620176 \n",
            "25: 2.395171718597412 \n",
            "30: 2.3805060227711996 \n",
            "35: 2.3691701003483363 \n",
            "40: 2.3599657297134398 \n",
            "45: 2.3537329302893744 \n",
            "50: 2.349967541694641 \n",
            "55: 2.344926556673917 \n",
            "60: 2.3415377259254457 \n",
            "65: 2.337994102331308 \n",
            "70: 2.3360272203172956 \n",
            "75: 2.3338978989919026 \n",
            "80: 2.331394559144974 \n",
            "85: 2.3293703696307015 \n",
            "90: 2.327591633796692 \n",
            "95: 2.3265369741540205 \n",
            "100: 2.3254865837097167 \n",
            "105: 2.3242548738207134 \n",
            "110: 2.322662854194641 \n",
            "115: 2.3219860035440196 \n",
            "120: 2.3214084347089132 \n",
            "125: 2.3207894458770753 \n",
            "130: 2.3202001113158004 \n",
            "135: 2.3193442009113454 \n",
            "140: 2.318551891190665 \n",
            "145: 2.31801176071167 \n",
            "150: 2.3174806467692055 \n",
            "155: 2.3169339872175647 \n",
            "160: 2.31651331782341 \n",
            "165: 2.316177009813713 \n",
            "170: 2.315733868935529 \n",
            "175: 2.3153022861480714 \n",
            "180: 2.3150207956631976 \n",
            "185: 2.3146305174440953 \n",
            "190: 2.3141515669069794 \n",
            "195: 2.31382890970279 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-cda7f316ccb0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# calcualte loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0madam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST ACCURACY\n",
        "model.eval()\n",
        "test_acc = 0.0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(-1, 28, 28)\n",
        "\n",
        "    outputs = model0(inputs)\n",
        "    # calucalte accuracy \n",
        "    out_labels = torch.argmax(outputs, 1).data\n",
        "    correct  = (out_labels == labels ).sum()\n",
        "    test_acc += correct\n",
        "        \n",
        "print('Test Accuracy: %.2f'%(test_acc / (i*64) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxz0UMouw4mn",
        "outputId": "1ba96076-0663-4c26-a785-60f16b100cc0"
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkVLDhHDygjy",
        "outputId": "5ec6c7f7-ab9c-47b8-8b82-bb7855744bc0"
      },
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9327.)"
            ]
          },
          "metadata": {},
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwgo1DVdsaxm",
        "outputId": "a659fd7f-c52c-43f7-8acd-3d617e7d7624"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8072, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From the tutorial"
      ],
      "metadata": {
        "id": "ba84JCzqZNZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all transformations\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "# download and load training dataset\n",
        "trainset2 = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader2 = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "1fKt_x3N1ipp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageRNN2(nn.Module):\n",
        "    \n",
        "    # declaraction of variables\n",
        "    def __init__(self, batch_size, n_steps, n_inputs, n_neurons, n_outputs):\n",
        "        super(ImageRNN2, self).__init__()\n",
        "        \n",
        "        self.n_neurons = n_neurons\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "        \n",
        "        self.basic_rnn = nn.RNN(self.n_inputs, self.n_neurons) \n",
        "        \n",
        "        self.FC = nn.Linear(self.n_neurons, self.n_outputs)\n",
        "    \n",
        "    # initialize hidden weights that have zero values\n",
        "    def init_hidden(self,):\n",
        "        # (num_layers, batch_size, n_neurons)\n",
        "        return (torch.zeros(1, self.batch_size, self.n_neurons))\n",
        "        \n",
        "    def forward(self, X):\n",
        "        # transforms X to dimensions: n_steps X batch_size X n_inputs\n",
        "        X = X.permute(1, 0, 2) \n",
        "        \n",
        "        self.batch_size = X.size(1)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        # lstm_out => n_steps, batch_size, n_neurons (hidden states for each time step)\n",
        "        # self.hidden => 1, batch_size, n_neurons (final state from each lstm_out)\n",
        "        lstm_out, self.hidden = self.basic_rnn(X, self.hidden)      \n",
        "        out = self.FC(self.hidden)\n",
        "        \n",
        "        return out.view(-1, self.n_outputs) # batch_size X n_output"
      ],
      "metadata": {
        "id": "WRl9HRUBZPpX"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# parameters \n",
        "N_STEPS = 28\n",
        "N_INPUTS = 28\n",
        "N_NEURONS = 150\n",
        "N_OUTPUTS = 10\n",
        "N_EPHOCS = 10"
      ],
      "metadata": {
        "id": "y8y7nYP9ZmAi"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "   \n",
        "import torch.optim as optim\n",
        "\n",
        "# Device: you can choose what device that you want to use during the training process\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model instance\n",
        "model = ImageRNN2(BATCH_SIZE, N_STEPS, N_INPUTS, N_NEURONS, N_OUTPUTS)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def get_accuracy(logit, target, batch_size):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batch_size\n",
        "    return accuracy.item()"
      ],
      "metadata": {
        "id": "UXnkOLg7Zhet"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPHOCS):  # loop over the dataset multiple times\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    # TRAINING ROUND\n",
        "    for i, data in enumerate(trainloader):\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # reset hidden states\n",
        "\n",
        "        \n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.view(-1, 28,28) \n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
        "         \n",
        "    model.eval()\n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \n",
        "          %(epoch, train_running_loss/i, train_acc/i))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "C9e9g2HNZmgt",
        "outputId": "34f23f6a-0e0f-46e6-c6a2-869bb835393f"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.6096 | Train Accuracy: 80.87\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-333-6624c74f183a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b0p30X_sZ0FI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}